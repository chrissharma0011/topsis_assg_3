# -*- coding: utf-8 -*-
"""ChrisSharma.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NZt0It9yPh1gO8JqbtsGzeChfrpkP32l
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

def topsis(matrix, weights, impacts):
    matrix = np.array(matrix, dtype=float)
    weights = np.array(weights, dtype=float)
    impacts = np.array(impacts)

    # Normalize the Decision Matrix
    norm_matrix = matrix / np.sqrt((matrix ** 2).sum(axis=0))

    # Multiply by Weights
    weighted_matrix = norm_matrix * weights

    # Determine Ideal and Negative-Ideal Solutions
    ideal_best = np.max(weighted_matrix, axis=0) * (impacts == '+') + np.min(weighted_matrix, axis=0) * (impacts == '-')
    ideal_worst = np.min(weighted_matrix, axis=0) * (impacts == '+') + np.max(weighted_matrix, axis=0) * (impacts == '-')

    # Calculate Separation Measures
    dist_best = np.sqrt(((weighted_matrix - ideal_best) ** 2).sum(axis=1))
    dist_worst = np.sqrt(((weighted_matrix - ideal_worst) ** 2).sum(axis=1))

    # Calculate Relative Closeness to Ideal Solution
    scores = dist_worst / (dist_best + dist_worst)

    return scores

# Define Models and Criteria
models = ['GPT-4', 'LLaMA 2', 'Mistral', 'Falcon', 'T5', 'GPT-NeoX', 'Bloom']
criteria = ['Perplexity', 'BLEU', 'ROUGE', 'Inference Speed', 'Memory Usage', 'Training Time']

# Sample Decision Matrix (rows = models, cols = criteria)
matrix = np.array([
    [10, 0.8, 0.75, 50, 20, 100],  # GPT-4
    [12, 0.75, 0.7, 45, 18, 90],   # LLaMA 2
    [11, 0.78, 0.72, 48, 17, 85],  # Mistral
    [13, 0.72, 0.65, 40, 22, 110], # Falcon
    [14, 0.7, 0.6, 38, 19, 95],    # T5
    [15, 0.68, 0.58, 35, 21, 105], # GPT-NeoX
    [16, 0.65, 0.55, 32, 23, 120], # Bloom
])

# Define Weights for Criteria
weights = [0.2, 0.2, 0.2, 0.15, 0.15, 0.1]

# Define Impact of Criteria (+ for beneficial, - for cost-based)
impacts = np.array(['-', '+', '+', '+', '-', '-'])

# Compute TOPSIS Scores
scores = topsis(matrix, weights, impacts)

# Rank Models Based on Scores
ranking = np.argsort(scores)[::-1]
ranked_models = [models[i] for i in ranking]

# Create Results DataFrame
results_df = pd.DataFrame({'Model': models, 'TOPSIS Score': scores})
results_df = results_df.sort_values(by='TOPSIS Score', ascending=False).reset_index(drop=True)

# Plot the Results
plt.figure(figsize=(10, 6))
sns.barplot(x=results_df['TOPSIS Score'], y=results_df['Model'], palette="viridis")
plt.xlabel("TOPSIS Score")
plt.ylabel("Model")
plt.title("TOPSIS Ranking of Pre-Trained Text Generation Models")
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.show()

# Display the results table
print(results_df)